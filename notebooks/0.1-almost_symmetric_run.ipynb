{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from pprint import pprint\n",
    "from mne_bids import read_raw_bids, BIDSPath, get_entity_vals\n",
    "from natsort import natsorted, index_natsorted, order_by_index\n",
    "import scipy\n",
    "from scipy import interp\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import random_projection\n",
    "\n",
    "from eztrack.fragility.linearsystem import DiscreteLinearSystem\n",
    "from eztrack.fragility.perturbationmodel import MinNormPerturbModel\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from analysis.fragility.posthoc import read_perturbation_result, run_svd_viz\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSTATION = \"home\"\n",
    "\n",
    "if WORKSTATION == \"home\":\n",
    "    # bids root to write BIDS data to\n",
    "    # the root of the BIDS dataset\n",
    "    root = Path(\"/Users/adam2392/Dropbox/epilepsy_bids/\")\n",
    "    output_dir = root / 'derivatives' / 'interictal'\n",
    "\n",
    "    figures_dir = output_dir / 'figures'\n",
    "\n",
    "    # path to excel layout file - would be changed to the datasheet locally\n",
    "    excel_fpath = Path(\n",
    "        \"/Users/adam2392/Dropbox/epilepsy_bids/sourcedata/organized_clinical_datasheet_raw.xlsx\"\n",
    "    )\n",
    "elif WORKSTATION == \"lab\":\n",
    "    root = Path(\"/home/adam2392/hdd/epilepsy_bids/\")\n",
    "    excel_fpath = Path(\n",
    "        \"/home/adam2392/hdd/epilepsy_bids/sourcedata/organized_clinical_datasheet_raw.xlsx\"\n",
    "    )\n",
    "\n",
    "    # output directory\n",
    "    output_dir = Path(\"/home/adam2392/hdd/epilepsy_bids\") / 'derivatives' / 'interictal'\n",
    "\n",
    "    # figures directory\n",
    "    figures_dir = output_dir / 'figures'\n",
    "\n",
    "figures_dir = root / 'derivatives' / 'rowvscol'\n",
    "figures_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing interictal task for pt1.\n",
      "Found ['01', '02', '03', '04'] runs for interictal task.\n",
      "TRYING TO READ RESULT FILENAME  sub-pt1_ses-presurgery_task-interictal_acq-ecog_run-01_desc-statematrix_ieeg.npy\n",
      "Loading /Users/adam2392/Dropbox/epilepsy_bids/derivatives/interictal/1000Hz/fragility/monopolar/sub-pt1/sub-pt1_ses-presurgery_task-interictal_acq-ecog_run-01_desc-statematrix_ieeg.npy, which exists: True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b37be006afb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'statematrix'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_perturbation_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mderiv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_basename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mA_mats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msidecar_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mpat_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_clinical_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "SUBJECTS = [\n",
    "#     'jh103',\n",
    "#     'jh105'\n",
    "    'pt1'\n",
    "]\n",
    "\n",
    "session = \"presurgery\"  # only one session\n",
    "task = \"interictal\"\n",
    "datatype = \"ieeg\"\n",
    "acquisition = \"ecog\"  # or SEEG\n",
    "extension = \".vhdr\"\n",
    "\n",
    "if acquisition == 'ecog':\n",
    "    ignore_acquisitions = ['seeg']\n",
    "elif acquisition == 'seeg':\n",
    "    ignore_acquisitions = ['ecog']\n",
    "\n",
    "reference = 'monopolar'\n",
    "sfreq = None  # either resample or don't\n",
    "\n",
    "# get the runs for this subject\n",
    "all_subjects = get_entity_vals(root, \"subject\")\n",
    "\n",
    "for subject in all_subjects:\n",
    "    if subject not in SUBJECTS:\n",
    "        continue\n",
    "    ignore_subs = [sub for sub in all_subjects if sub != subject]\n",
    "    all_tasks = get_entity_vals(root, \"task\", ignore_subjects=ignore_subs)\n",
    "    ignore_tasks = [tsk for tsk in all_tasks if tsk != task]\n",
    "\n",
    "    print(f\"Analyzing {task} task for {subject}.\")\n",
    "    ignore_tasks = [tsk for tsk in all_tasks if tsk != task]\n",
    "    runs = get_entity_vals(\n",
    "        root, 'run', ignore_subjects=ignore_subs,\n",
    "        ignore_tasks=ignore_tasks,\n",
    "        ignore_acquisitions=ignore_acquisitions\n",
    "    )\n",
    "    print(f'Found {runs} runs for {task} task.')\n",
    "\n",
    "    deriv_path = (output_dir\n",
    "                  # /  'nodepth'\n",
    "                  / '1000Hz'\n",
    "                  / \"fragility\"\n",
    "                  / reference\n",
    "                  / f\"sub-{subject}\")\n",
    "    \n",
    "    for idx, run in enumerate(runs):\n",
    "        # create path for the dataset\n",
    "        bids_path = BIDSPath(\n",
    "            subject=subject,\n",
    "            session=session,\n",
    "            task=task,\n",
    "            run=run,\n",
    "            datatype=datatype,\n",
    "            acquisition=acquisition,\n",
    "            suffix=datatype,\n",
    "            root=root,\n",
    "#             extension=extension,\n",
    "        )\n",
    "        source_basename = bids_path.basename\n",
    "        description = 'statematrix'\n",
    "        result = read_perturbation_result(deriv_path, source_basename, description)\n",
    "        A_mats, result_info, sidecar_json = result[0]\n",
    "        \n",
    "        pat_dict = read_clinical_excel(excel_fpath, subject=subject)\n",
    "        \n",
    "        # extract the SOZ channels\n",
    "        soz_chs = pat_dict[ClinicalContactColumns.SOZ_CONTACTS.value]\n",
    "        epz_chs = pat_dict[ClinicalContactColumns.SPREAD_CONTACTS.value]\n",
    "        rz_chs = pat_dict[ClinicalContactColumns.RESECTED_CONTACTS.value]\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Transition Probability Matrix Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'radius': 1.05,\n",
    "    'perturb_type': 'C',\n",
    "    'method_to_use': 'dc',\n",
    "}\n",
    "pert_model = MinNormPerturbModel(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "variance = 1\n",
    "m = 100\n",
    "\n",
    "# generate sub-gaussian matrix with independent entries\n",
    "A = np.random.normal(loc=mean, scale=variance, size=(m, m))\n",
    "A_symm = (A + A.T) / 2\n",
    "\n",
    "# generate data w/ it\n",
    "dlds = DiscreteLinearSystem(A=A_symm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dlds.reconstruct(x0=np.ones((m,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sickkids",
   "language": "python",
   "name": "sickkids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
